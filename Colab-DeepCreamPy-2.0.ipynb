{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepcreampy_2.0_working.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j16BPC-GDG8N",
        "colab_type": "code",
        "outputId": "f48b0ae0-7574-433e-c5a2-cccf6e647cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# Check your GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed May  6 22:15:31 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCXy5WBgVc3o",
        "colab_type": "text"
      },
      "source": [
        "# Copy files from Drive or Place them manually\n",
        "\n",
        "If you want to use drive, create these paths inside your Google Drive and place your files there.\n",
        "- deepcreampy/decensor_input\n",
        "- deepcreampy/decensor_input_original\n",
        "\n",
        "Colab location:\n",
        " - /content/DeepCreamPy-2.0.0-beta/decensor_input\n",
        " - /content/DeepCreamPy-2.0.0-beta/decensor_input_original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXp6H4RxDJPV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c7b73d16-454c-45bb-ef9f-21435c937212"
      },
      "source": [
        "# Connect Google Drive and copy files from Drive, if you want to use Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print('Google Drive connected.')\n",
        "!cp -r '/content/drive/My Drive/deepcreampy/decensor_input/' '/content/DeepCreamPy-2.0.0-beta/'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Google Drive connected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GlscfVXIVK5",
        "colab_type": "code",
        "outputId": "92722def-fb9c-4b83-910e-791424c96f14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Download model files\n",
        "!wget https://github.com/deeppomf/DeepCreamPy/archive/v2.0.0-beta.tar.gz\n",
        "!tar -C /content/ -xvf \"/content/v2.0.0-beta.tar.gz\"\n",
        "\n",
        "# Place model files\n",
        "!sudo apt install unzip\n",
        "!pip install gdown\n",
        "%cd /content/DeepCreamPy-2.0.0-beta/models\n",
        "\n",
        "!gdown https://drive.google.com/uc?id=1IMwzqZUuRnTv5jcuKdvZx-RZweknww5x\n",
        "!unzip \"/content/DeepCreamPy-2.0.0-beta/models/09-11-2019 DCPv2 model.zip\"\n",
        "\n",
        "# Move model files\n",
        "%cd '/content/DeepCreamPy-2.0.0-beta/models/09-11-2019 DCPv2 model'\n",
        "\n",
        "!mv '/content/DeepCreamPy-2.0.0-beta/models/09-11-2019 DCPv2 model/bar' '/content/DeepCreamPy-2.0.0-beta/models/bar'\n",
        "!mv '/content/DeepCreamPy-2.0.0-beta/models/09-11-2019 DCPv2 model/mosaic' '/content/DeepCreamPy-2.0.0-beta/models/mosaic'\n",
        "!rmdir '/content/DeepCreamPy-2.0.0-beta/models/09-11-2019 DCPv2 model'\n",
        "%cd '/content/DeepCreamPy-2.0.0-beta'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-06 23:19:28--  https://github.com/deeppomf/DeepCreamPy/archive/v2.0.0-beta.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/deeppomf/DeepCreamPy/tar.gz/v2.0.0-beta [following]\n",
            "--2020-05-06 23:19:29--  https://codeload.github.com/deeppomf/DeepCreamPy/tar.gz/v2.0.0-beta\n",
            "Resolving codeload.github.com (codeload.github.com)... 13.229.189.0\n",
            "Connecting to codeload.github.com (codeload.github.com)|13.229.189.0|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘v2.0.0-beta.tar.gz’\n",
            "\n",
            "v2.0.0-beta.tar.gz      [          <=>       ]   8.95M  4.05MB/s    in 2.2s    \n",
            "\n",
            "2020-05-06 23:19:31 (4.05 MB/s) - ‘v2.0.0-beta.tar.gz’ saved [9385187]\n",
            "\n",
            "DeepCreamPy-2.0.0-beta/\n",
            "DeepCreamPy-2.0.0-beta/.github/\n",
            "DeepCreamPy-2.0.0-beta/.github/ISSUE_TEMPLATE/\n",
            "DeepCreamPy-2.0.0-beta/.github/ISSUE_TEMPLATE/bug_report.md\n",
            "DeepCreamPy-2.0.0-beta/.github/ISSUE_TEMPLATE/feature_request.md\n",
            "DeepCreamPy-2.0.0-beta/EULA.txt\n",
            "DeepCreamPy-2.0.0-beta/README.md\n",
            "DeepCreamPy-2.0.0-beta/config.py\n",
            "DeepCreamPy-2.0.0-beta/decensor.py\n",
            "DeepCreamPy-2.0.0-beta/decensor_input/\n",
            "DeepCreamPy-2.0.0-beta/decensor_input/.gitignore\n",
            "DeepCreamPy-2.0.0-beta/decensor_input/mermaid_censored.png\n",
            "DeepCreamPy-2.0.0-beta/decensor_input_original/\n",
            "DeepCreamPy-2.0.0-beta/decensor_input_original/.gitignore\n",
            "DeepCreamPy-2.0.0-beta/decensor_input_original/.gitkeep.txt\n",
            "DeepCreamPy-2.0.0-beta/decensor_output/\n",
            "DeepCreamPy-2.0.0-beta/decensor_output/.gitignore\n",
            "DeepCreamPy-2.0.0-beta/decensor_output/mermaid_censored.png\n",
            "DeepCreamPy-2.0.0-beta/docs/\n",
            "DeepCreamPy-2.0.0-beta/docs/ACKNOWLEDGEMENTS.md\n",
            "DeepCreamPy-2.0.0-beta/docs/DONORS.md\n",
            "DeepCreamPy-2.0.0-beta/docs/FAQ.md\n",
            "DeepCreamPy-2.0.0-beta/docs/INSTALLATION.md\n",
            "DeepCreamPy-2.0.0-beta/docs/INSTALLATION_BINARY.md\n",
            "DeepCreamPy-2.0.0-beta/docs/TROUBLESHOOTING.md\n",
            "DeepCreamPy-2.0.0-beta/docs/TROUBLESHOOTING_DECENSORS.md\n",
            "DeepCreamPy-2.0.0-beta/docs/USAGE.md\n",
            "DeepCreamPy-2.0.0-beta/file.py\n",
            "DeepCreamPy-2.0.0-beta/libs/\n",
            "DeepCreamPy-2.0.0-beta/libs/utils.py\n",
            "DeepCreamPy-2.0.0-beta/model.py\n",
            "DeepCreamPy-2.0.0-beta/models/\n",
            "DeepCreamPy-2.0.0-beta/models/.gitignore\n",
            "DeepCreamPy-2.0.0-beta/module.py\n",
            "DeepCreamPy-2.0.0-beta/ops.py\n",
            "DeepCreamPy-2.0.0-beta/readme_images/\n",
            "DeepCreamPy-2.0.0-beta/readme_images/mermaid_collage.png\n",
            "DeepCreamPy-2.0.0-beta/readme_images/mermaid_face_censored.png\n",
            "DeepCreamPy-2.0.0-beta/readme_images/mermaid_face_censored_bad_decensor.png\n",
            "DeepCreamPy-2.0.0-beta/readme_images/mermaid_face_censored_bad_edge.png\n",
            "DeepCreamPy-2.0.0-beta/readme_images/mermaid_face_censored_bad_edge_zoom.png\n",
            "DeepCreamPy-2.0.0-beta/readme_images/mermaid_face_censored_bad_incomplete.png\n",
            "DeepCreamPy-2.0.0-beta/readme_images/mermaid_face_censored_bad_incomplete_zoom.png\n",
            "DeepCreamPy-2.0.0-beta/readme_images/mermaid_face_censored_good.png\n",
            "DeepCreamPy-2.0.0-beta/readme_images/mermaid_face_censored_good_zoom.png\n",
            "DeepCreamPy-2.0.0-beta/requirements.txt\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.38.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.12.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.9)\n",
            "/content/DeepCreamPy-2.0.0-beta/models\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IMwzqZUuRnTv5jcuKdvZx-RZweknww5x\n",
            "To: /content/DeepCreamPy-2.0.0-beta/models/09-11-2019 DCPv2 model.zip\n",
            "261MB [00:04, 53.1MB/s]\n",
            "Archive:  /content/DeepCreamPy-2.0.0-beta/models/09-11-2019 DCPv2 model.zip\n",
            "   creating: 09-11-2019 DCPv2 model/\n",
            "   creating: 09-11-2019 DCPv2 model/bar/\n",
            "  inflating: 09-11-2019 DCPv2 model/bar/Train_775000.data-00000-of-00001  \n",
            "  inflating: 09-11-2019 DCPv2 model/bar/checkpoint  \n",
            "  inflating: 09-11-2019 DCPv2 model/bar/Train_775000.index  \n",
            "  inflating: 09-11-2019 DCPv2 model/bar/Train_775000.meta  \n",
            "   creating: 09-11-2019 DCPv2 model/mosaic/\n",
            "  inflating: 09-11-2019 DCPv2 model/mosaic/checkpoint  \n",
            "  inflating: 09-11-2019 DCPv2 model/mosaic/Train_290000.data-00000-of-00001  \n",
            "  inflating: 09-11-2019 DCPv2 model/mosaic/Train_290000.index  \n",
            "  inflating: 09-11-2019 DCPv2 model/mosaic/Train_290000.meta  \n",
            "/content/DeepCreamPy-2.0.0-beta/models/09-11-2019 DCPv2 model\n",
            "/content/DeepCreamPy-2.0.0-beta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCZF2pPRC44-",
        "colab_type": "code",
        "outputId": "3a54a171-c9bd-4dc8-9666-72189f4578b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd '/content/DeepCreamPy-2.0.0-beta'\n",
        "!pip install tensorflow==1.15\n",
        "\n",
        "!pip install keras==2.2.4\n",
        "\n",
        "!pip install scipy\n",
        "\n",
        "!pip install opencv-python\n",
        "\n",
        "!wget https://raw.githubusercontent.com/deeppomf/DeepCreamPy/master/requirements-gpu.txt\n",
        "!pip install -r requirements-gpu.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DeepCreamPy-2.0.0-beta\n",
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 42kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 52.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.34.2)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.2.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.28.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.9.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=04431d8761d62de865ee81ccc152f3b4ba759c01fea82e198694cd28239c72a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, gast, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.2.0rc4\n",
            "    Uninstalling tensorflow-2.2.0rc4:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc4\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 12.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.3)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "Successfully installed keras-2.2.4\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.3)\n",
            "--2020-05-06 23:22:34--  https://raw.githubusercontent.com/deeppomf/DeepCreamPy/master/requirements-gpu.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 403 [text/plain]\n",
            "Saving to: ‘requirements-gpu.txt’\n",
            "\n",
            "requirements-gpu.tx 100%[===================>]     403  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-06 23:22:35 (25.3 MB/s) - ‘requirements-gpu.txt’ saved [403/403]\n",
            "\n",
            "Collecting absl-py==0.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.5MB/s \n",
            "\u001b[?25hCollecting astor==0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements-gpu.txt (line 3)) (0.2.2)\n",
            "Collecting google-pasta==0.1.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.4MB/s \n",
            "\u001b[?25hCollecting grpcio==1.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/5d/b434403adb2db8853a97828d3d19f2032e79d630e0d11a8e95d243103a11/grpcio-1.22.0-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 32.5MB/s \n",
            "\u001b[?25hCollecting h5py==2.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 50.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: Keras-Applications==1.0.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements-gpu.txt (line 7)) (1.0.8)\n",
            "Requirement already satisfied: Keras-Preprocessing==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements-gpu.txt (line 8)) (1.1.0)\n",
            "Collecting Markdown==3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 13.5MB/s \n",
            "\u001b[?25hCollecting numpy==1.17.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/b9/bda9781f0a74b90ebd2e046fde1196182900bd4a8e1ea503d3ffebc50e7c/numpy-1.17.0-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\n",
            "\u001b[K     |████████████████████████████████| 20.4MB 167kB/s \n",
            "\u001b[?25hCollecting opencv-python==4.1.0.25\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/d2/a2dbf83d4553ca6b3701d91d75e42fe50aea97acdc00652dca515749fb5d/opencv_python-4.1.0.25-cp36-cp36m-manylinux1_x86_64.whl (26.6MB)\n",
            "\u001b[K     |████████████████████████████████| 26.6MB 121kB/s \n",
            "\u001b[?25hCollecting Pillow==6.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/fd/bbbc569f98f47813c50a116b539d97b3b17a86ac7a309f83b2022d26caf2/Pillow-6.2.2-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 40.2MB/s \n",
            "\u001b[?25hCollecting protobuf==3.9.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/f4/a27952733796330cd17c17ea1f974459f5fefbbad119c0f296a6d807fec3/protobuf-3.9.1-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 53.2MB/s \n",
            "\u001b[?25hCollecting PySide2==5.13.0\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\",)': /packages/3d/a1/9300c616621ba1d1a3426d98b59cd5403045eafaa0263e68e7d4d48a49e4/PySide2-5.13.0-5.13.0-cp35.cp36.cp37-abi3-manylinux1_x86_64.whl\u001b[0m\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/a1/9300c616621ba1d1a3426d98b59cd5403045eafaa0263e68e7d4d48a49e4/PySide2-5.13.0-5.13.0-cp35.cp36.cp37-abi3-manylinux1_x86_64.whl (152.9MB)\n",
            "\u001b[K     |████████████████████████████████| 152.9MB 73kB/s \n",
            "\u001b[?25hCollecting scipy==1.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/4c/5f81e7264b0a7a8bd570810f48cd346ba36faedbd2ba255c873ad556de76/scipy-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2MB 54.3MB/s \n",
            "\u001b[?25hCollecting shiboken2==5.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/e2/e121fa55a759a286588a4017f57f34c03e8b35722131a2189a4f0e84bbac/shiboken2-5.13.0-5.13.0-cp35.cp36.cp37-abi3-manylinux1_x86_64.whl (792kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six==1.12.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements-gpu.txt (line 17)) (1.12.0)\n",
            "Collecting tensorboard==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 48.0MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 55.7MB/s \n",
            "\u001b[?25hCollecting tensorflow-gpu==1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/ca/58e40e5077fa2a92004f398d705a288e958434f123938f4ce75ffe25b64b/tensorflow_gpu-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (411.0MB)\n",
            "\u001b[K     |████████████████████████████████| 411.0MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements-gpu.txt (line 21)) (1.1.0)\n",
            "Collecting Werkzeug==0.15.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/ab/d3bed6b92042622d24decc7aadc8877badf18aeca1571045840ad4956d3f/Werkzeug-0.15.5-py2.py3-none-any.whl (328kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 45.3MB/s \n",
            "\u001b[?25hCollecting wrapt==1.11.2\n",
            "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
            "Requirement already satisfied: setuptools>=36 in /usr/local/lib/python3.6/dist-packages (from Markdown==3.1.1->-r requirements-gpu.txt (line 9)) (46.1.3)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.14.0->-r requirements-gpu.txt (line 18)) (0.34.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements-gpu.txt (line 20)) (3.2.1)\n",
            "Building wheels for collected packages: absl-py, wrapt\n",
            "  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for absl-py: filename=absl_py-0.7.1-cp36-none-any.whl size=117848 sha256=fac9b5ea844cc7da7318fc5bed6c06120d044f8e3d308e54a9e083b06bcea5ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/98/38/46cbcc5a93cfea5492d19c38562691ddb23b940176c14f7b48\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.11.2-cp36-cp36m-linux_x86_64.whl size=67533 sha256=0de6dd01572ab3aea65dddca190f1b7ff9f61226744aaf690a7949da3cab2790\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
            "Successfully built absl-py wrapt\n",
            "\u001b[31mERROR: umap-learn 0.4.2 has requirement scipy>=1.3.1, but you'll have scipy 1.3.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 1.15.2 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 1.15.2 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: absl-py, astor, google-pasta, grpcio, numpy, h5py, Markdown, opencv-python, Pillow, protobuf, shiboken2, PySide2, scipy, Werkzeug, tensorboard, tensorflow-estimator, wrapt, tensorflow-gpu\n",
            "  Found existing installation: absl-py 0.9.0\n",
            "    Uninstalling absl-py-0.9.0:\n",
            "      Successfully uninstalled absl-py-0.9.0\n",
            "  Found existing installation: astor 0.8.1\n",
            "    Uninstalling astor-0.8.1:\n",
            "      Successfully uninstalled astor-0.8.1\n",
            "  Found existing installation: google-pasta 0.2.0\n",
            "    Uninstalling google-pasta-0.2.0:\n",
            "      Successfully uninstalled google-pasta-0.2.0\n",
            "  Found existing installation: grpcio 1.28.1\n",
            "    Uninstalling grpcio-1.28.1:\n",
            "      Successfully uninstalled grpcio-1.28.1\n",
            "  Found existing installation: numpy 1.18.3\n",
            "    Uninstalling numpy-1.18.3:\n",
            "      Successfully uninstalled numpy-1.18.3\n",
            "  Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "  Found existing installation: Markdown 3.2.1\n",
            "    Uninstalling Markdown-3.2.1:\n",
            "      Successfully uninstalled Markdown-3.2.1\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "  Found existing installation: protobuf 3.10.0\n",
            "    Uninstalling protobuf-3.10.0:\n",
            "      Successfully uninstalled protobuf-3.10.0\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: Werkzeug 1.0.1\n",
            "    Uninstalling Werkzeug-1.0.1:\n",
            "      Successfully uninstalled Werkzeug-1.0.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: wrapt 1.12.1\n",
            "    Uninstalling wrapt-1.12.1:\n",
            "      Successfully uninstalled wrapt-1.12.1\n",
            "Successfully installed Markdown-3.1.1 Pillow-6.2.2 PySide2-5.13.0 Werkzeug-0.15.5 absl-py-0.7.1 astor-0.8.0 google-pasta-0.1.7 grpcio-1.22.0 h5py-2.9.0 numpy-1.17.0 opencv-python-4.1.0.25 protobuf-3.9.1 scipy-1.3.0 shiboken2-5.13.0 tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.15.2 wrapt-1.11.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "google",
                  "grpc",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_AamorxHhVF",
        "colab_type": "code",
        "outputId": "681adb64-02dd-4228-b79e-2a3292f298b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd '/content/DeepCreamPy-2.0.0-beta'\n",
        "!python decensor.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DeepCreamPy-2.0.0-beta\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0506 23:25:32.163728 140666916509568 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0506 23:25:32.208218 140666916509568 module_wrapper.py:139] From /content/DeepCreamPy-2.0.0-beta/model.py:7: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0506 23:25:32.208420 140666916509568 module_wrapper.py:139] From /content/DeepCreamPy-2.0.0-beta/model.py:7: The name tf.logging.ERROR is deprecated. Please use tf.compat.v1.logging.ERROR instead.\n",
            "\n",
            "2020-05-06 23:25:39.558452: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2020-05-06 23:25:39.563916: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000125000 Hz\n",
            "2020-05-06 23:25:39.564172: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1e2f100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-06 23:25:39.564222: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-05-06 23:25:39.567981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-05-06 23:25:39.786545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-06 23:25:39.787345: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1e2f640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-06 23:25:39.787373: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-05-06 23:25:39.789013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-06 23:25:39.789569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-06 23:25:39.804033: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-05-06 23:25:40.014445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-05-06 23:25:40.108880: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-05-06 23:25:40.135848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-05-06 23:25:40.375925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-05-06 23:25:40.510165: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-05-06 23:25:41.018721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-06 23:25:41.018958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-06 23:25:41.019701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-06 23:25:41.020252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-06 23:25:41.020380: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-05-06 23:25:41.021898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-06 23:25:41.021947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-06 23:25:41.021966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-06 23:25:41.022188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-06 23:25:41.022796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-06 23:25:41.023363: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-05-06 23:25:41.023407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2020-05-06 23:25:54.058104: W tensorflow/core/graph/graph_constructor.cc:1491] Importing a graph with a lower producer version 38 into an existing graph with producer version 134. Shape inference will have run different parts of the graph with different producer versions.\n",
            "--------------------------------------------------------------------------\n",
            "Decensoring the image ./decensor_input/mermaid_censored.png\n",
            "Found 17 censored regions in this image!\n",
            "2020-05-06 23:26:40.566201: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-06 23:26:45.724641: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "1 out of 17 regions decensored.\n",
            "2 out of 17 regions decensored.\n",
            "3 out of 17 regions decensored.\n",
            "4 out of 17 regions decensored.\n",
            "5 out of 17 regions decensored.\n",
            "6 out of 17 regions decensored.\n",
            "7 out of 17 regions decensored.\n",
            "8 out of 17 regions decensored.\n",
            "9 out of 17 regions decensored.\n",
            "10 out of 17 regions decensored.\n",
            "11 out of 17 regions decensored.\n",
            "12 out of 17 regions decensored.\n",
            "13 out of 17 regions decensored.\n",
            "14 out of 17 regions decensored.\n",
            "15 out of 17 regions decensored.\n",
            "16 out of 17 regions decensored.\n",
            "17 out of 17 regions decensored.\n",
            "Decensored image saved to ./decensor_output/mermaid_censored.png!\n",
            "--------------------------------------------------------------------------\n",
            "\n",
            "Decensoring complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3GCYxFwXkhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy results back to Drive, if you used Drive\n",
        "!cp -r '/content/DeepCreamPy-2.0.0-beta/decensor_output' '/content/drive/My Drive/deepcreampy/'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}